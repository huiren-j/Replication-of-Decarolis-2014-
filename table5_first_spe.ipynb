{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16127, 31)\n"
     ]
    }
   ],
   "source": [
    "#main_taberconley_controls.do\n",
    "#sample.do\n",
    "#!pip install linearmodels\n",
    "#!pip install econtools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from linearmodels import PanelOLS\n",
    "import statsmodels.api as sm\n",
    "import econtools as econ\n",
    "import econtools.metrics as mt\n",
    "\n",
    "df = pd.read_stata('data/Authority.dta')\n",
    "print(df.shape)\n",
    "#list(df.columns)\n",
    "\n",
    "#construct work category dummy\n",
    "df['OG03_dummy'] = 0\n",
    "df.loc[(df['work_category']=='OG03')&(df['work_category']!=''),'OG03_dummy'] = 1\n",
    "\n",
    "df['OG01_dummy'] = 0\n",
    "df.loc[(df['work_category']=='OG01')&(df['work_category']!=''),'OG01_dummy'] = 1\n",
    "\n",
    "df['OG_rest_dummy'] = 0\n",
    "df.loc[(df['OG01_dummy']!=1)&(df['OG03_dummy']!=1)&(df['work_category']!=''),'OG_rest_dummy'] = 1\n",
    "\n",
    "df['OG_dummy'] = 0\n",
    "df.loc[df['work_category'].str[0:2] == 'OG','OG_dummy'] = 1\n",
    "\n",
    "df['OS_dummy'] = 0\n",
    "df.loc[df['work_category'].str[0:2] == 'OS','OS_dummy'] = 1\n",
    "\n",
    "#treated vs controls\n",
    "df['trend'] = df['year'] - 1999\n",
    "\n",
    "df['trend_treat'] = df['trend']\n",
    "df.loc[(df['authority_code']!=3090272)&(df['authority_code']!=3070001),'trend_treat'] = 0\n",
    "#15225 real change made / no zeros in df['trend']\n",
    "#print(df['trend_treat'].value_counts()) chekced\n",
    "\n",
    "df['trend_control'] = df['trend']\n",
    "df.loc[(df['authority_code']==3090272)|(df['authority_code']==3070001),'trend_control'] = 0\n",
    "#902 real change made\n",
    "#print(df['trend_control'].value_counts()) checked\n",
    "\n",
    "#PA specifics\n",
    "df = df.sort_values(by='authority_code',ascending=True)\n",
    "#auth = econ.group_id(df, cols = 'authority_code')\n",
    "#print(auth) #dataframe\n",
    "\n",
    "auth_list = df['authority_code'].values.tolist()\n",
    "auth_list = list(set(auth_list))\n",
    "\n",
    "#겹치는 부분 = authority_code야\n",
    "#id_auth = group_id + 1 if df의 auth code == auth의 code\n",
    "\n",
    "df['id_auth'] = 0\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(auth_list)):\n",
    "        if df.loc[i,'authority_code'] == auth_list[j]:\n",
    "            df.loc[i,'id_auth'] = j+1\n",
    "#id_auth =  econ.group_id(df, cols='authority_code')\n",
    "#print(id_auth)\n",
    "#print(df['id_auth'].values.tolist())\n",
    "\n",
    "work_dum = pd.get_dummies(df['work_category'])\n",
    "year_dum = pd.get_dummies(df['year'])\n",
    "work_list = list(work_dum.columns)\n",
    "year_list = list(year_dum.columns)\n",
    "\n",
    "df_dum = pd.concat([year_dum, work_dum],axis = 1)\n",
    "df = pd.concat([df, df_dum],axis = 1)\n",
    "\n",
    "#for statement check            \n",
    "#df.head\n",
    "#print(max(df['id_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2016, 93)\n"
     ]
    }
   ],
   "source": [
    "#keep the observations need\n",
    "#df = untouched \n",
    "df1 = df\n",
    "df1 = df1[((df1['turin_co_sample'] == 1)|(df1['turin_pr_sample'] == 1))&((df1['post_experience']>=5)|(df1['post_experience'].isnull()==True)) &((df1['pre_experience']>=5)|(df1['pre_experience'].isnull()==True)) &(df1['missing']==0)]\n",
    "#df_pr = df1[(df1['turin_co_sample'] != 1)&(df1['turin_pr_sample'] == 1)&(df1['post_experience']>=5) &(df1['pre_experience']>=5) &(df1['missing']==0)]\n",
    "#df_co_pr = df1[(df1['turin_co_sample'] == 1)&(df1['turin_pr_sample'] == 1)&(df1['post_experience']>=5) &(df1['pre_experience']>=5) &(df1['missing']==0)]\n",
    "#df1 = pd.concat([df_co,df_pr,df_co_pr])\n",
    "df1= df1[(df1['ctrl_pop_turin_co_sample']==1) | (df1['ctrl_pop_turin_pr_sample']==1) | (df1['ctrl_exp_turin_co_sample']==1) | (df1['ctrl_exp_turin_pr_sample']==1) | (df1['ctrl_pop_exp_turin_co_sample']==1) | (df1['ctrl_pop_exp_turin_pr_sample']==1)]\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruct trend_pa (another version)\n",
    "id_auth_group =  econ.group_id(df1, cols='id_auth')\n",
    "id_auth_group['group_id'] = id_auth_group['group_id'] +1\n",
    "#print(id_auth_group)\n",
    "\n",
    "df1['id_auth_remained'] = 0\n",
    "for i in range(len(df1)):\n",
    "    for j in range(len(id_auth_group)):\n",
    "        if df1.iloc[i,df1.columns.get_loc('id_auth')] == id_auth_group.loc[j, 'id_auth']:\n",
    "            df1.iloc[i,df1.columns.get_loc('id_auth_remained')] = id_auth_group.loc[j, 'group_id']\n",
    "id_auth_remained_dum = pd.get_dummies(df1['id_auth_remained']).rename(columns=lambda x: 'id_auth_remained' + str(x))\n",
    "df1 = pd.concat([df1, id_auth_remained_dum],axis = 1)\n",
    "\n",
    "for i in range(len(id_auth_group)):\n",
    "    df1['trend_pa_remained'+str(i+1)] =0\n",
    "    col_num_tr = df1.columns.get_loc('trend_pa_remained'+str(i+1))\n",
    "    col_num_id = df1.columns.get_loc('id_auth_remained'+str(i+1))\n",
    "    for j in range(len(df1)):\n",
    "        if df1.iloc[j, col_num_id]==1 and df1.iloc[j, df1.columns.get_loc('authority_code')]!= 3090272 and df1.iloc[j,df1.columns.get_loc('authority_code')]!=3070001:\n",
    "            df1.iloc[j ,col_num_tr] = df1.iloc[j, df1.columns.get_loc('trend')]\n",
    "    df1.drop(['id_auth_remained'+str(i+1)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(df1[df1['work_category']==\"\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thxkn\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:193: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\thxkn\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1685: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "Dependent variable:\tdiscount\n",
      "N:\t\t\t1262\n",
      "R-squared:\t\t0.6393\n",
      "Estimation method:\tOLS\n",
      "VCE method:\t\tCluster\n",
      "  Cluster variable:\t  auth_anno\n",
      "  No. of clusters:\t  101\n",
      "Fixed effects by:\tauthority_code\n",
      "  No. of FE:\t\t  15\n",
      "=======================================================\n",
      "               coeff    se      t   p>t  CI_low CI_high\n",
      "fpsb_auction  11.992 1.315  9.117 0.000   9.382  14.602\n",
      "reserve_price  0.000 0.000  5.993 0.000   0.000   0.000\n",
      "OG02           0.205 0.629  0.326 0.745  -1.043   1.452\n",
      "OG03          -0.583 0.545 -1.070 0.287  -1.665   0.498\n",
      "OG04          -4.754 3.344 -1.422 0.158 -11.389   1.881\n",
      "OG06           0.852 0.655  1.300 0.196  -0.448   2.151\n",
      "OG07           4.509 5.121  0.881 0.381  -5.651  14.668\n",
      "OG08           0.801 1.606  0.499 0.619  -2.384   3.986\n",
      "OG10           8.419 0.515 16.337 0.000   7.396   9.441\n",
      "OG11           5.680 1.058  5.367 0.000   3.580   7.780\n",
      "OG12           6.017 1.940  3.101 0.003   2.168   9.866\n",
      "OS01          -2.534 1.204 -2.104 0.038  -4.923  -0.145\n",
      "OS02           9.521 1.405  6.777 0.000   6.734  12.308\n",
      "OS05           5.753 1.053  5.464 0.000   3.664   7.842\n",
      "OS06           4.690 1.612  2.910 0.004   1.492   7.888\n",
      "OS07           3.299 0.713  4.625 0.000   1.884   4.714\n",
      "OS08           5.234 3.077  1.701 0.092  -0.872  11.339\n",
      "OS10          14.516 1.663  8.729 0.000  11.217  17.815\n",
      "OS11          -5.731 1.015 -5.644 0.000  -7.746  -3.716\n",
      "OS12          17.361 1.334 13.012 0.000  14.714  20.008\n",
      "OS14           3.964 0.847  4.679 0.000   2.283   5.645\n",
      "OS18          -1.769 1.951 -0.907 0.367  -5.640   2.102\n",
      "OS19           3.349 0.914  3.663 0.000   1.535   5.164\n",
      "OS21           3.718 1.773  2.097 0.038   0.201   7.235\n",
      "OS22           0.573 1.255  0.456 0.649  -1.918   3.063\n",
      "OS23           0.977 2.191  0.446 0.657  -3.370   5.324\n",
      "OS24           1.094 1.892  0.578 0.564  -2.659   4.848\n",
      "OS26           0.727 0.849  0.856 0.394  -0.958   2.412\n",
      "OS28           3.819 1.229  3.107 0.002   1.381   6.258\n",
      "OS30           7.976 1.579  5.053 0.000   4.844  11.108\n",
      "OS34          12.971 3.044  4.262 0.000   6.933  19.009\n",
      "2001.0         1.839 1.038  1.772 0.079  -0.220   3.897\n",
      "2002.0        -0.014 0.932 -0.015 0.988  -1.862   1.835\n",
      "2003.0        -0.451 0.998 -0.452 0.652  -2.431   1.528\n",
      "2004.0         1.242 0.945  1.313 0.192  -0.634   3.117\n",
      "2005.0         3.158 1.029  3.068 0.003   1.116   5.200\n",
      "2006.0         4.007 1.148  3.489 0.001   1.729   6.286\n",
      "=======================================================\n",
      " =======================================================\n",
      "Dependent variable:\tdiscount\n",
      "N:\t\t\t1262\n",
      "R-squared:\t\t0.6393\n",
      "Estimation method:\tOLS\n",
      "VCE method:\t\tCluster\n",
      "  Cluster variable:\t  authority_code\n",
      "  No. of clusters:\t  15\n",
      "Fixed effects by:\tauthority_code\n",
      "  No. of FE:\t\t  15\n",
      "=======================================================\n",
      "               coeff    se       t   p>t  CI_low CI_high\n",
      "fpsb_auction  11.992 0.782  15.328 0.000  10.314  13.670\n",
      "reserve_price  0.000 0.000   8.551 0.000   0.000   0.000\n",
      "OG02           0.205 0.881   0.232 0.820  -1.686   2.095\n",
      "OG03          -0.583 0.971  -0.601 0.558  -2.665   1.499\n",
      "OG04          -4.754 3.416  -1.391 0.186 -12.082   2.574\n",
      "OG06           0.852 0.992   0.858 0.405  -1.277   2.980\n",
      "OG07           4.509 5.175   0.871 0.398  -6.591  15.609\n",
      "OG08           0.801 1.422   0.563 0.582  -2.249   3.851\n",
      "OG10           8.419 0.477  17.647 0.000   7.396   9.442\n",
      "OG11           5.680 1.414   4.016 0.001   2.646   8.714\n",
      "OG12           6.017 1.485   4.053 0.001   2.833   9.201\n",
      "OS01          -2.534 1.086  -2.333 0.035  -4.863  -0.204\n",
      "OS02           9.521 0.691  13.785 0.000   8.040  11.003\n",
      "OS05           5.753 1.628   3.534 0.003   2.261   9.244\n",
      "OS06           4.690 1.511   3.105 0.008   1.450   7.931\n",
      "OS07           3.299 0.811   4.067 0.001   1.559   5.039\n",
      "OS08           5.234 2.393   2.187 0.046   0.101  10.366\n",
      "OS10          14.516 1.673   8.677 0.000  10.928  18.104\n",
      "OS11          -5.731 0.452 -12.690 0.000  -6.700  -4.762\n",
      "OS12          17.361 1.380  12.584 0.000  14.402  20.320\n",
      "OS14           3.964 1.102   3.596 0.003   1.600   6.329\n",
      "OS18          -1.769 2.450  -0.722 0.482  -7.024   3.486\n",
      "OS19           3.349 0.614   5.456 0.000   2.033   4.666\n",
      "OS21           3.718 1.680   2.213 0.044   0.115   7.322\n",
      "OS22           0.573 1.005   0.570 0.578  -1.582   2.728\n",
      "OS23           0.977 2.629   0.372 0.716  -4.661   6.615\n",
      "OS24           1.094 3.240   0.338 0.741  -5.854   8.043\n",
      "OS26           0.727 0.918   0.792 0.442  -1.241   2.695\n",
      "OS28           3.819 0.675   5.659 0.000   2.372   5.267\n",
      "OS30           7.976 1.584   5.035 0.000   4.578  11.373\n",
      "OS34          12.971 3.383   3.834 0.002   5.715  20.227\n",
      "2001.0         1.839 1.427   1.288 0.219  -1.222   4.900\n",
      "2002.0        -0.014 1.317  -0.010 0.992  -2.838   2.811\n",
      "2003.0        -0.451 1.213  -0.372 0.715  -3.054   2.151\n",
      "2004.0         1.242 1.307   0.950 0.358  -1.561   4.044\n",
      "2005.0         3.158 1.152   2.741 0.016   0.687   5.629\n",
      "2006.0         4.007 1.546   2.592 0.021   0.691   7.323\n",
      "=======================================================\n",
      " =======================================================\n",
      "Dependent variable:\tdiscount\n",
      "N:\t\t\t1262\n",
      "R-squared:\t\t0.3582\n",
      "Estimation method:\tOLS\n",
      "VCE method:\t\tCluster\n",
      "  Cluster variable:\t  auth_anno\n",
      "  No. of clusters:\t  101\n",
      "=======================================================\n",
      "                        coeff          se      t   p>t       CI_low     CI_high\n",
      "reserve_price          -0.000       0.000 -3.853 0.000       -0.000      -0.000\n",
      "fiscal_efficiency       2.000         nan    nan   nan          nan         nan\n",
      "auth_year_3_2005       13.500         nan    nan   nan          nan         nan\n",
      "auth_year_3_2002       14.500         nan    nan   nan          nan         nan\n",
      "auth_year_3_2006       36.000         nan    nan   nan          nan         nan\n",
      "auth_year_3_2000        7.000 2309399.086  0.000 1.000 -4581775.011 4581789.011\n",
      "auth_year_3_2001       26.500         nan    nan   nan          nan         nan\n",
      "auth_year_3_2003        8.500         nan    nan   nan          nan         nan\n",
      "auth_year_3_2004       15.000         nan    nan   nan          nan         nan\n",
      "auth_year_4_2005       28.000         nan    nan   nan          nan         nan\n",
      "auth_year_4_2002       12.000         nan    nan   nan          nan         nan\n",
      "auth_year_4_2006       22.000         nan    nan   nan          nan         nan\n",
      "auth_year_4_2001       17.000         nan    nan   nan          nan         nan\n",
      "auth_year_4_2003        7.500 2038225.688  0.000 1.000 -4043774.214 4043789.214\n",
      "auth_year_4_2004       13.500         nan    nan   nan          nan         nan\n",
      "auth_year_6_2005       23.000 1955022.894  0.000 1.000 -3878686.740 3878732.740\n",
      "auth_year_6_2002       15.000 2557334.260  0.000 1.000 -5073663.335 5073693.335\n",
      "auth_year_6_2006       15.000 1262641.122  0.000 1.000 -2505029.024 2505059.024\n",
      "auth_year_6_2000       17.000         nan    nan   nan          nan         nan\n",
      "auth_year_6_2001       14.000         nan    nan   nan          nan         nan\n",
      "auth_year_6_2003       15.500         nan    nan   nan          nan         nan\n",
      "auth_year_6_2004       12.000 1443352.903  0.000 1.000 -2863559.052 2863583.052\n",
      "auth_year_9_2005       16.500         nan    nan   nan          nan         nan\n",
      "auth_year_9_2002        9.500         nan    nan   nan          nan         nan\n",
      "auth_year_9_2006        7.000         nan    nan   nan          nan         nan\n",
      "auth_year_9_2000       19.000  900723.261  0.000 1.000 -1786990.296 1787028.296\n",
      "auth_year_9_2001       15.000         nan    nan   nan          nan         nan\n",
      "auth_year_9_2003        3.500         nan    nan   nan          nan         nan\n",
      "auth_year_9_2004       15.000         nan    nan   nan          nan         nan\n",
      "auth_year_16_2005      13.000 2682966.014  0.000 1.000 -5322915.156 5322941.156\n",
      "auth_year_16_2006       1.000         nan    nan   nan          nan         nan\n",
      "auth_year_16_2000       7.500         nan    nan   nan          nan         nan\n",
      "auth_year_16_2001      13.000         nan    nan   nan          nan         nan\n",
      "auth_year_20_2005      16.500         nan    nan   nan          nan         nan\n",
      "auth_year_20_2002      11.500 1421608.864  0.000 1.000 -2820419.997 2820442.997\n",
      "auth_year_20_2006      15.500         nan    nan   nan          nan         nan\n",
      "auth_year_20_2000       9.000         nan    nan   nan          nan         nan\n",
      "auth_year_20_2001      15.500         nan    nan   nan          nan         nan\n",
      "auth_year_20_2003       3.000 1556696.071  0.000 1.000 -3088437.667 3088443.667\n",
      "auth_year_20_2004      13.500         nan    nan   nan          nan         nan\n",
      "auth_year_25_2005      18.000         nan    nan   nan          nan         nan\n",
      "auth_year_25_2002      17.000         nan    nan   nan          nan         nan\n",
      "auth_year_25_2006      14.500         nan    nan   nan          nan         nan\n",
      "auth_year_25_2000      11.000         nan    nan   nan          nan         nan\n",
      "auth_year_25_2001      16.000         nan    nan   nan          nan         nan\n",
      "auth_year_25_2003      14.000 1949192.313  0.000 1.000 -3867128.032 3867156.032\n",
      "auth_year_25_2004      16.000  578520.956  0.000 1.000 -1147753.099 1147785.099\n",
      "auth_year_30_2005      14.000         nan    nan   nan          nan         nan\n",
      "auth_year_30_2002       8.000 1432426.451  0.000 1.000 -2841885.281 2841901.281\n",
      "auth_year_30_2006       7.500         nan    nan   nan          nan         nan\n",
      "auth_year_30_2000      -1.000         nan    nan   nan          nan         nan\n",
      "auth_year_30_2001      17.500         nan    nan   nan          nan         nan\n",
      "auth_year_30_2003      10.000         nan    nan   nan          nan         nan\n",
      "auth_year_30_2004      15.500 1609019.303  0.000 1.000 -3192232.970 3192263.970\n",
      "auth_year_1246_2005    15.000         nan    nan   nan          nan         nan\n",
      "auth_year_1246_2002     9.500         nan    nan   nan          nan         nan\n",
      "auth_year_1246_2006    15.500  751795.155  0.000 1.000 -1491524.675 1491555.675\n",
      "auth_year_1246_2000     2.000         nan    nan   nan          nan         nan\n",
      "auth_year_1246_2001    14.000 1173770.269  0.000 1.000 -2328712.784 2328740.784\n",
      "auth_year_1246_2003     6.000         nan    nan   nan          nan         nan\n",
      "auth_year_1246_2004    10.500         nan    nan   nan          nan         nan\n",
      "auth_year_1708_2005    13.000         nan    nan   nan          nan         nan\n",
      "auth_year_1708_2002     5.500 2722836.228  0.000 1.000 -5402024.026 5402035.026\n",
      "auth_year_1708_2006    15.000         nan    nan   nan          nan         nan\n",
      "auth_year_1708_2000     8.000         nan    nan   nan          nan         nan\n",
      "auth_year_1708_2001     5.000 1252594.154  0.000 1.000 -2485106.125 2485116.125\n",
      "auth_year_1708_2003     4.500         nan    nan   nan          nan         nan\n",
      "auth_year_1708_2004     7.500 1424790.879  0.000 1.000 -2826737.024 2826752.024\n",
      "auth_year_1739_2005    16.500         nan    nan   nan          nan         nan\n",
      "auth_year_1739_2002    13.500         nan    nan   nan          nan         nan\n",
      "auth_year_1739_2006    16.500         nan    nan   nan          nan         nan\n",
      "auth_year_1739_2000     8.000         nan    nan   nan          nan         nan\n",
      "auth_year_1739_2001     8.500 1126871.326  0.000 1.000 -2235672.117 2235689.117\n",
      "auth_year_1739_2003    13.000         nan    nan   nan          nan         nan\n",
      "auth_year_1739_2004    13.000         nan    nan   nan          nan         nan\n",
      "auth_year_1768_2005    17.000         nan    nan   nan          nan         nan\n",
      "auth_year_1768_2002    12.000         nan    nan   nan          nan         nan\n",
      "auth_year_1768_2006    15.500         nan    nan   nan          nan         nan\n",
      "auth_year_1768_2000    12.500         nan    nan   nan          nan         nan\n",
      "auth_year_1768_2001    16.000         nan    nan   nan          nan         nan\n",
      "auth_year_1768_2003    15.500         nan    nan   nan          nan         nan\n",
      "auth_year_1768_2004    11.500         nan    nan   nan          nan         nan\n",
      "auth_year_1858_2005    11.000         nan    nan   nan          nan         nan\n",
      "auth_year_1858_2002    10.000 2164584.468  0.000 1.000 -4294463.933 4294483.933\n",
      "auth_year_1858_2006    14.000         nan    nan   nan          nan         nan\n",
      "auth_year_1858_2000    10.500         nan    nan   nan          nan         nan\n",
      "auth_year_1858_2001    13.000         nan    nan   nan          nan         nan\n",
      "auth_year_1858_2003    10.500         nan    nan   nan          nan         nan\n",
      "auth_year_1858_2004     9.000         nan    nan   nan          nan         nan\n",
      "auth_year_1866_2005    13.000 2162663.377  0.000 1.000 -4290649.544 4290675.544\n",
      "auth_year_1866_2002    11.500         nan    nan   nan          nan         nan\n",
      "auth_year_1866_2006    15.000         nan    nan   nan          nan         nan\n",
      "auth_year_1866_2000    11.000  940869.542  0.000 1.000 -1866647.373 1866669.373\n",
      "auth_year_1866_2001    11.250         nan    nan   nan          nan         nan\n",
      "auth_year_1866_2003    12.000         nan    nan   nan          nan         nan\n",
      "auth_year_1866_2004    12.000         nan    nan   nan          nan         nan\n",
      "auth_year_3090272_2005 31.500         nan    nan   nan          nan         nan\n",
      "auth_year_3090272_2002 16.000         nan    nan   nan          nan         nan\n",
      "auth_year_3090272_2006 36.000         nan    nan   nan          nan         nan\n",
      "auth_year_3090272_2000 17.000         nan    nan   nan          nan         nan\n",
      "auth_year_3090272_2001 20.000         nan    nan   nan          nan         nan\n",
      "auth_year_3090272_2003 30.500         nan    nan   nan          nan         nan\n",
      "auth_year_3090272_2004 32.000         nan    nan   nan          nan         nan\n",
      "=======================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thxkn\\anaconda3\\lib\\site-packages\\econtools\\metrics\\core.py:203: RuntimeWarning: invalid value encountered in sqrt\n",
      "  se = pd.Series(np.sqrt(np.diagonal(vce)), index=vce.columns)\n",
      "C:\\Users\\thxkn\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "C:\\Users\\thxkn\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "C:\\Users\\thxkn\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1827: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  cond2 = (x >= np.asarray(_b)) & cond0\n"
     ]
    }
   ],
   "source": [
    "#create dummies pa-year\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# mutlicollinearity function\n",
    "def calc_vif(X):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)\n",
    "treatment = ['turin_co_sample'] #, 'turin_pr_sample']\n",
    "group = [ 'ctrl_exp'] #, 'ctrl_pop', 'ctrl_pop_exp']\n",
    "outcomes = ['discount'] #, 'delay_ratio', 'overrun_ratio', 'days_to_award'] \n",
    "c_outcomes = 1\n",
    "i = 5\n",
    "\n",
    "for t in treatment:\n",
    "    for g in group:\n",
    "        for o in outcomes:\n",
    "            #matrix = nc_ + o + t \n",
    "            df1 = df1[(df1[t]==1) & (df1[g +'_' + t]==1) & (df1['post_experience']>=i) & (df1['pre_experience']>=i)& (df1['post_experience'].isnull()==False) & (df1['pre_experience'].isnull()==False) & (df1['missing']==0) & (df1[o].isnull()==False) & (df1['fiscal_efficiency'].isnull()==False) & (df1['reserve_price'].isnull()==False)&(df1['municipality'].isnull()==False)]\n",
    "            df1.sort_values(by = 'authority_code', ascending = True)\n",
    "            #for j in range(len(df_tab5)):\n",
    "            #    if df_tab5.loc[j,'authority_code']!=df[[:,j],'authority_code']:\n",
    "            #        df_tab5['ind'] = 1\n",
    "            #line61-64 skip\n",
    "            \n",
    "            #create dummies for administration-year pairs \n",
    "            all_years = df1['year'].unique()\n",
    "            all_authorities = df1['authority_code'].unique()\n",
    "            auth_year_reg_col = []\n",
    "            for auth in all_authorities:\n",
    "                for yr in all_years:\n",
    "                    df1['auth_year_' + str(int(auth))+'_' + str(int(yr))] = 0\n",
    "                    auth_year_reg_col.append('auth_year_' + str(int(auth))+'_' + str(int(yr)))\n",
    "                    df1.loc[(df1['year']==yr) & (df1['authority_code']==auth), 'auth_year_' + str(int(auth))+'_' + str(int(yr)) ] = 1\n",
    "           \n",
    "            # create dummies for work category\n",
    "            all_categories = df1['work_category'].unique()\n",
    "            i = 1\n",
    "            for cat in all_categories:\n",
    "                df1['cat_'+cat] = 0\n",
    "                df1.loc[df1['work_category']==cat, 'cat'+cat] =1\n",
    "                if i == 1:\n",
    "                #line91\n",
    "                    i = i+1\n",
    "                #else:\n",
    "                #line 95\n",
    "       \n",
    "            ### Regression first stage \n",
    "            #make a exog list\n",
    "            reg_col = []\n",
    "            for i in work_list:\n",
    "                reg_col.append(i)\n",
    "            for j in year_list:\n",
    "                reg_col.append(j)\n",
    "            \n",
    "            exog_var = ['fpsb_auction','reserve_price','municipality']\n",
    "            exog = exog_var + reg_col \n",
    "            #i_authority_code 안 만드는 이유 = fe_name에 들어가있어서\n",
    "\n",
    "            #vif cal\n",
    "            #check multicollinearity\n",
    "            X = df1.loc[:,exog]\n",
    "            vif = calc_vif(X)\n",
    "            #print(vif)\n",
    "\n",
    "\n",
    "            #delete from col list\n",
    "            for i in range(len(vif)):\n",
    "                if np.isnan(vif.loc[i, 'VIF']) == True:\n",
    "                    reg_col.remove(vif.loc[i, 'variables'])\n",
    "                elif vif.loc[i,'VIF'] > 10:\n",
    "                    for j in exog_var:\n",
    "                        if str(vif.loc[i,'variables']) is j and vif.loc[i,'variables'] is not 'fpsb_auction' and vif.loc[i,'variables'] is not 'id_auth':\n",
    "                            exog_var.remove(vif.loc[i,'variables'])\n",
    "                \n",
    "            exog = exog_var + reg_col\n",
    "            exog.remove(2000)\n",
    "            exog.remove('OG01')\n",
    "            exog.remove('municipality')\n",
    "    \n",
    "            #1. reg\n",
    "            fe_reg_1 = mt.reg(df1, o, exog, fe_name = 'authority_code', cluster = 'auth_anno')\n",
    "            \n",
    "            #2. reg\n",
    "            fe_reg_2 = mt.reg(df1, o, exog, fe_name = 'authority_code', cluster = 'authority_code')\n",
    "            \n",
    "            #3. reg\n",
    "            reg_col = auth_year_reg_col\n",
    "            for cat in all_categories:\n",
    "                reg_col.append('cat_'+cat)\n",
    "            exog_var = ['reserve_price','municipality','fiscal_efficiency']\n",
    "            exog = exog_var + reg_col\n",
    "            \n",
    "            X = df1.loc[:,exog]\n",
    "            vif = calc_vif(X)\n",
    "            #print(vif)\n",
    "            for i in range(len(vif)):\n",
    "                if np.isnan(vif.loc[i, 'VIF']) == True:\n",
    "                    reg_col.remove(vif.loc[i, 'variables'])\n",
    "                '''elif vif.loc[i,'VIF'] > 10:\n",
    "                    for j in exog:\n",
    "                        exog_var.remove(vif.loc[i,'variables'])'''\n",
    "                \n",
    "            exog = exog_var + reg_col\n",
    "            exog.remove('municipality')\n",
    "            \n",
    "            fe_reg_3 = mt.reg(df1, o, exog, cluster = 'auth_anno')\n",
    "            print(fe_reg_1, fe_reg_2, fe_reg_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummies for work category\n",
    "all_categories = df['work_cateogory'].unique()\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "i = 1\n",
    "for cat in all_categories:\n",
    "    df['cat_'+cat] = 0\n",
    "    df.loc[df['work_category']==cat, 'cat'+cat] =1\n",
    "    if i == 1:\n",
    "        #line91\n",
    "        i = i+1\n",
    "    else:\n",
    "        #line 95\n",
    "        \n",
    "# Regression first stage \n",
    "    # mutlicollinearity function\n",
    "    def calc_vif(X):\n",
    "\n",
    "        # Calculating VIF\n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"variables\"] = X.columns\n",
    "        vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "        return(vif)\n",
    "\n",
    "    #iteration\n",
    "#for o in outcome: create dum pa-year이랑 연결됨\n",
    "    #days_to_award(4,6)\n",
    "    idx = df_reg_co[df_reg_co[o].isnull()==True].index\n",
    "    df_name = df_reg_co.drop(idx)\n",
    "    \n",
    "    #vif cal\n",
    "    #first, make a column list\n",
    "    reg_col = []\n",
    "    for i in work_list:\n",
    "        reg_col.append(i)\n",
    "    for j in year_list:\n",
    "        reg_col.append(j)\n",
    "        \n",
    "        reg_col.append('auth_year_' + auth + yr)\n",
    "    #i_authority_code 안 만드는 이유 = fe_name에 들어가있어서\n",
    "    exog_var = ['fpsb_auction','reserve_price','municipality']\n",
    "    exog = exog_var + reg_col \n",
    "\n",
    "\n",
    "    #check multicollinearity\n",
    "    X = df_name.loc[:,exog]\n",
    "    vif = calc_vif(X)\n",
    "    #print(vif)\n",
    "\n",
    "\n",
    "    #delete from col list\n",
    "    for i in range(len(vif)):\n",
    "        if np.isnan(vif.loc[i, 'VIF']) == True:\n",
    "            reg_col.remove(vif.loc[i, 'variables'])\n",
    "        elif vif.loc[i,'VIF'] > 10:\n",
    "            for j in exog_var:\n",
    "                if str(vif.loc[i,'variables']) is j and vif.loc[i,'variables'] is not 'fpsb_auction' and vif.loc[i,'variables'] is not 'id_auth':\n",
    "                    exog_var.remove(vif.loc[i,'variables'])\n",
    "                \n",
    "    exog = exog_var + reg_col\n",
    "    exog.remove(2000)\n",
    "    exog.remove('OG01')\n",
    "    #exog.remove('municipality')\n",
    "    \n",
    "    #1. reg\n",
    "    fe_reg = mt.reg(df_name, o, exog, fe_name = 'authority_code', cluster = 'auth_anno')\n",
    "    #print(fe_reg) \n",
    "    if 'c_outcomes' == 1:\n",
    "        #outreg2\n",
    "    else:\n",
    "        #outreg2\n",
    "        \n",
    "    #2. reg cluster(authority_code) line110\n",
    "    fe_reg = mt.reg(df_name, o, exog, fe_name = 'authority_code', cluster = 'authority_code')\n",
    "    if 'c_outcomes' == 1:\n",
    "        #outreg\n",
    "    else: \n",
    "        #outreg\n",
    "    \n",
    "    \n",
    "    \n",
    "    ####3. reg line 118\n",
    "    def calc_vif(X):\n",
    "\n",
    "        # Calculating VIF\n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"variables\"] = X.columns\n",
    "        vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "        return(vif)\n",
    "\n",
    "    #iteration\n",
    "    #days_to_award(4,6)\n",
    "    idx = df_reg_co[df_reg_co[o].isnull()==True].index\n",
    "    df_name = df_reg_co.drop(idx)\n",
    "    \n",
    "    #vif cal\n",
    "    #first, make a column list\n",
    "    reg_col = []\n",
    "    for i in all_categories:\n",
    "        reg_col.append('cat_'+i)\n",
    "    for auth in all_authorities:\n",
    "        for yr in all_years:\n",
    "             reg_col.append('auth_year_' + auth + yr)\n",
    "    \n",
    "    exog_var = ['fiscal efficiency','reserve_price','municipality']\n",
    "    exog = exog_var + reg_col \n",
    "\n",
    "\n",
    "    #check multicollinearity\n",
    "    X = df_name.loc[:,exog]\n",
    "    vif = calc_vif(X)\n",
    "    #print(vif)\n",
    "\n",
    "\n",
    "    #delete from col list\n",
    "    for i in range(len(vif)):\n",
    "        if np.isnan(vif.loc[i, 'VIF']) == True:\n",
    "            reg_col.remove(vif.loc[i, 'variables'])\n",
    "        elif vif.loc[i,'VIF'] > 10:\n",
    "            for j in exog_var:\n",
    "                if str(vif.loc[i,'variables']) is j and vif.loc[i,'variables'] is not 'fpsb_auction' and vif.loc[i,'variables'] is not 'id_auth':\n",
    "                    exog_var.remove(vif.loc[i,'variables'])\n",
    "                \n",
    "    exog = exog_var + reg_col\n",
    "    #exog.remove('municipality')\n",
    "    \n",
    "    #1. reg\n",
    "    fe_reg = mt.reg(df_name, o, exog, cluster = 'auth_anno')\n",
    "    \n",
    "#line 120-121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create weights (123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Keep only beta coefficients for state*year terms *(130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Core conley-taber method*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/* Predict residuals from regression */(137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/* Create d tilde variable*/\n",
    "df_tab5 = df_tab5.sort_values(by = 'year', ascending = True)\n",
    "df_tab5.loc[(df['authority_code']==3090272) | (df['authority_code']==3070001),'djtga'] = df['authority_code'].mean()\n",
    "df_tab5['djt'] = df['djtga'].sum()\n",
    "\n",
    "df_tab5 = df_tab5.sort_values(by = 'authority_code',ascending = True)\n",
    "df_tab5['meandjt'] = df['djt'].mean()\n",
    "df_tab5['tilde'] = df['djt'] - df['meandjt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line148 Obtain difference in differences coefficient*/\n",
    "#line149 re-normalize weights*/\n",
    "\n",
    "df.loc[(df['authority_code']==3090272) | (df['authority_code']==3070001), 'tot_weights'] = df['weights']\n",
    "df['new_weights'] = df['weights']/df['tot_weights']\n",
    "mod_wls = sm.WLS(eta, dtil, weights=df['new_weights']).fit()\n",
    "df.drop(['new_weights','tot_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/* Simulations for each public administration\n",
    "\n",
    "#line160\n",
    "for auth in all_authorities:\n",
    "\n",
    "\n",
    "#line 177,178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence intervals\n",
    "\n",
    "#line 231"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
